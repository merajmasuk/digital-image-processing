{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4peqJAzw/rD5CZktc1CO4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merajmasuk/digital-image-processing/blob/main/notebooks/CNN_%7C_Pooling_layer_operation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pooling operation involves sliding a two-dimensional filter over each channel of feature map and summarising the features lying within the region covered by the filter. \n",
        "For a feature map having dimensions nh x nw x nc, the dimensions of output obtained after a pooling layer is \n",
        " \n",
        "\n",
        "    (nh - f + 1) / s x (nw - f + 1)/s x nc\n",
        "\n",
        "where, \n",
        "\n",
        "```\n",
        "-> nh - height of feature map\n",
        "-> nw - width of feature map\n",
        "-> nc - number of channels in the feature map\n",
        "-> f  - size of filter\n",
        "-> s  - stride length\n",
        "```\n",
        "\n",
        "A common CNN model architecture is to have a number of convolution and pooling layers stacked one after the other. \n",
        "Why to use Pooling Layers?\n",
        "\n",
        "- Pooling layers are used to reduce the dimensions of the feature maps. Thus, it reduces the number of parameters to learn and the amount of computation performed in the network.\n",
        "- The pooling layer summarises the features present in a region of the feature map generated by a convolution layer. So, further operations are performed on summarised features instead of precisely positioned features generated by the convolution layer. This makes the model more robust to variations in the position of the features in the input image. "
      ],
      "metadata": {
        "id": "f7WuCF2eoHkV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zaLm7AFAn3Ec"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "\n",
        "image = np.array([[2, 2, 7, 3],\n",
        "                  [9, 4, 6, 1],\n",
        "                  [8, 5, 2, 4],\n",
        "                  [3, 1, 2, 6]], dtype=np.float32)\n",
        "image = image.reshape(1, 4, 4, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# max pooling\n",
        "from keras.layers import MaxPooling2D\n",
        "\n",
        "model = Sequential(\n",
        "    [MaxPooling2D(pool_size = 2, strides = 2)])\n",
        " \n",
        "# generate pooled output\n",
        "output = model.predict(image)\n",
        " \n",
        "# print output image\n",
        "output = np.squeeze(output)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM00eguto4wU",
        "outputId": "1dd3fd3f-4ee2-4491-86d0-c50382e682c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 49ms/step\n",
            "[[9. 7.]\n",
            " [8. 6.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# average pooling\n",
        "from keras.layers import AveragePooling2D\n",
        "\n",
        "model = Sequential(\n",
        "    [AveragePooling2D(pool_size = 2, strides = 2)])\n",
        " \n",
        "# generate pooled output\n",
        "output = model.predict(image)\n",
        " \n",
        "# print output image\n",
        "output = np.squeeze(output)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pzn-ZVs8pFri",
        "outputId": "acc42fea-6d02-41c2-cc06-8fb7cd8c6faa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc5cc88820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "[[4.25 4.25]\n",
            " [4.25 3.5 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gobal (max, average) pooling\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "gm_model = Sequential(\n",
        "    [GlobalMaxPooling2D()])\n",
        " \n",
        "# define ga_model containing just a single global-average pooling layer\n",
        "ga_model = Sequential(\n",
        "    [GlobalAveragePooling2D()])\n",
        " \n",
        "# generate pooled output\n",
        "gm_output = gm_model.predict(image)\n",
        "ga_output = ga_model.predict(image)\n",
        " \n",
        "# print output image\n",
        "gm_output = np.squeeze(gm_output)\n",
        "ga_output = np.squeeze(ga_output)\n",
        "print(\"gm_output: \", gm_output)\n",
        "print(\"ga_output: \", ga_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omnRxRCHsNl8",
        "outputId": "0f45ec82-1d42-49b1-c9a6-19167b64e6e5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fbc5cc893f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "gm_output:  9.0\n",
            "ga_output:  4.0625\n"
          ]
        }
      ]
    }
  ]
}